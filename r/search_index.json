[["index.html", "Apache Arrow R Cookbook 1 Preface 1.1 What is Arrow? 1.2 Alternative resources", " Apache Arrow R Cookbook 1 Preface This cookbook aims to provide a number of recipes showing how to perform common tasks using arrow. This version of the cookbook works with arrow &gt;= 6.0.0, but in future we will maintain different versions for the last few major R package releases. 1.1 What is Arrow? Apache Arrow is a cross-language development platform for in-memory analytics. The arrow R package provides a low-level interface to much of the functionality available in the C++ implementation, as well as a higher-level interface to the compute functionality via an implementation of the dplyr API. 1.2 Alternative resources For a complete reference guide to the functions in arrow, as well as vignettes, see the pkgdown site. If you have any requests for new recipes, please open a ticket via the cookbook’s GitHub Issues page. If you have any Arrow feature requests to make or bugs to report, please open an issue on the project JIRA "],["reading-and-writing-data.html", "2 Reading and Writing Data 2.1 Introduction 2.2 Convert from a data frame to an Arrow Table 2.3 Convert data from an Arrow Table to a data frame 2.4 Write a Parquet file 2.5 Read a Parquet file 2.6 Read a Parquet file from S3 2.7 Filter columns while reading a Parquet file 2.8 Write an IPC/Feather V2 file 2.9 Read a Feather file 2.10 Write streaming IPC files 2.11 Read streaming IPC files 2.12 Read CSV files 2.13 Write CSV files 2.14 Read JSON files 2.15 Write partitioned data 2.16 Read partitioned data 2.17 Write compressed data 2.18 Read compressed data", " 2 Reading and Writing Data 2.1 Introduction This chapter contains recipes related to reading and writing data using Apache Arrow. When reading files into R using Apache Arrow, you can choose to read in your file as either a data frame or as an Arrow Table object. There are a number of circumstances in which you may want to read in the data as an Arrow Table: your dataset is large and if you load it into memory, it may lead to performance issues you want faster performance from your dplyr queries you want to be able to take advantage of Arrow’s compute functions 2.2 Convert from a data frame to an Arrow Table You want to convert an existing data.frame or tibble object into an Arrow Table. 2.2.1 Solution air_table &lt;- arrow_table(airquality) air_table ## Table ## 153 rows x 6 columns ## $Ozone &lt;int32&gt; ## $Solar.R &lt;int32&gt; ## $Wind &lt;double&gt; ## $Temp &lt;int32&gt; ## $Month &lt;int32&gt; ## $Day &lt;int32&gt; ## ## See $metadata for additional Schema metadata 2.3 Convert data from an Arrow Table to a data frame You want to convert an Arrow Table to a data frame to view the data or work with it in your usual analytics pipeline. 2.3.1 Solution air_df &lt;- as.data.frame(air_table) air_df ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 ## 11 7 NA 6.9 74 5 11 ## 12 16 256 9.7 69 5 12 ## 13 11 290 9.2 66 5 13 ## 14 14 274 10.9 68 5 14 ## 15 18 65 13.2 58 5 15 ## 16 14 334 11.5 64 5 16 ## 17 34 307 12.0 66 5 17 ## 18 6 78 18.4 57 5 18 ## 19 30 322 11.5 68 5 19 ## 20 11 44 9.7 62 5 20 ## 21 1 8 9.7 59 5 21 ## 22 11 320 16.6 73 5 22 ## 23 4 25 9.7 61 5 23 ## 24 32 92 12.0 61 5 24 ## 25 NA 66 16.6 57 5 25 ## 26 NA 266 14.9 58 5 26 ## 27 NA NA 8.0 57 5 27 ## 28 23 13 12.0 67 5 28 ## 29 45 252 14.9 81 5 29 ## 30 115 223 5.7 79 5 30 ## 31 37 279 7.4 76 5 31 ## 32 NA 286 8.6 78 6 1 ## 33 NA 287 9.7 74 6 2 ## 34 NA 242 16.1 67 6 3 ## 35 NA 186 9.2 84 6 4 ## 36 NA 220 8.6 85 6 5 ## 37 NA 264 14.3 79 6 6 ## 38 29 127 9.7 82 6 7 ## 39 NA 273 6.9 87 6 8 ## 40 71 291 13.8 90 6 9 ## 41 39 323 11.5 87 6 10 ## 42 NA 259 10.9 93 6 11 ## 43 NA 250 9.2 92 6 12 ## 44 23 148 8.0 82 6 13 ## 45 NA 332 13.8 80 6 14 ## 46 NA 322 11.5 79 6 15 ## 47 21 191 14.9 77 6 16 ## 48 37 284 20.7 72 6 17 ## 49 20 37 9.2 65 6 18 ## 50 12 120 11.5 73 6 19 ## 51 13 137 10.3 76 6 20 ## 52 NA 150 6.3 77 6 21 ## 53 NA 59 1.7 76 6 22 ## 54 NA 91 4.6 76 6 23 ## 55 NA 250 6.3 76 6 24 ## 56 NA 135 8.0 75 6 25 ## 57 NA 127 8.0 78 6 26 ## 58 NA 47 10.3 73 6 27 ## 59 NA 98 11.5 80 6 28 ## 60 NA 31 14.9 77 6 29 ## 61 NA 138 8.0 83 6 30 ## 62 135 269 4.1 84 7 1 ## 63 49 248 9.2 85 7 2 ## 64 32 236 9.2 81 7 3 ## 65 NA 101 10.9 84 7 4 ## 66 64 175 4.6 83 7 5 ## 67 40 314 10.9 83 7 6 ## 68 77 276 5.1 88 7 7 ## 69 97 267 6.3 92 7 8 ## 70 97 272 5.7 92 7 9 ## 71 85 175 7.4 89 7 10 ## 72 NA 139 8.6 82 7 11 ## 73 10 264 14.3 73 7 12 ## 74 27 175 14.9 81 7 13 ## 75 NA 291 14.9 91 7 14 ## 76 7 48 14.3 80 7 15 ## 77 48 260 6.9 81 7 16 ## 78 35 274 10.3 82 7 17 ## 79 61 285 6.3 84 7 18 ## 80 79 187 5.1 87 7 19 ## 81 63 220 11.5 85 7 20 ## 82 16 7 6.9 74 7 21 ## 83 NA 258 9.7 81 7 22 ## 84 NA 295 11.5 82 7 23 ## 85 80 294 8.6 86 7 24 ## 86 108 223 8.0 85 7 25 ## 87 20 81 8.6 82 7 26 ## 88 52 82 12.0 86 7 27 ## 89 82 213 7.4 88 7 28 ## 90 50 275 7.4 86 7 29 ## 91 64 253 7.4 83 7 30 ## 92 59 254 9.2 81 7 31 ## 93 39 83 6.9 81 8 1 ## 94 9 24 13.8 81 8 2 ## 95 16 77 7.4 82 8 3 ## 96 78 NA 6.9 86 8 4 ## 97 35 NA 7.4 85 8 5 ## 98 66 NA 4.6 87 8 6 ## 99 122 255 4.0 89 8 7 ## 100 89 229 10.3 90 8 8 ## 101 110 207 8.0 90 8 9 ## 102 NA 222 8.6 92 8 10 ## 103 NA 137 11.5 86 8 11 ## 104 44 192 11.5 86 8 12 ## 105 28 273 11.5 82 8 13 ## 106 65 157 9.7 80 8 14 ## 107 NA 64 11.5 79 8 15 ## 108 22 71 10.3 77 8 16 ## 109 59 51 6.3 79 8 17 ## 110 23 115 7.4 76 8 18 ## 111 31 244 10.9 78 8 19 ## 112 44 190 10.3 78 8 20 ## 113 21 259 15.5 77 8 21 ## 114 9 36 14.3 72 8 22 ## 115 NA 255 12.6 75 8 23 ## 116 45 212 9.7 79 8 24 ## 117 168 238 3.4 81 8 25 ## 118 73 215 8.0 86 8 26 ## 119 NA 153 5.7 88 8 27 ## 120 76 203 9.7 97 8 28 ## 121 118 225 2.3 94 8 29 ## 122 84 237 6.3 96 8 30 ## 123 85 188 6.3 94 8 31 ## 124 96 167 6.9 91 9 1 ## 125 78 197 5.1 92 9 2 ## 126 73 183 2.8 93 9 3 ## 127 91 189 4.6 93 9 4 ## 128 47 95 7.4 87 9 5 ## 129 32 92 15.5 84 9 6 ## 130 20 252 10.9 80 9 7 ## 131 23 220 10.3 78 9 8 ## 132 21 230 10.9 75 9 9 ## 133 24 259 9.7 73 9 10 ## 134 44 236 14.9 81 9 11 ## 135 21 259 15.5 76 9 12 ## 136 28 238 6.3 77 9 13 ## 137 9 24 10.9 71 9 14 ## 138 13 112 11.5 71 9 15 ## 139 46 237 6.9 78 9 16 ## 140 18 224 13.8 67 9 17 ## 141 13 27 10.3 76 9 18 ## 142 24 238 10.3 68 9 19 ## 143 16 201 8.0 82 9 20 ## 144 13 238 12.6 64 9 21 ## 145 23 14 9.2 71 9 22 ## 146 36 139 10.3 81 9 23 ## 147 7 49 10.3 69 9 24 ## 148 14 20 16.6 63 9 25 ## 149 30 193 6.9 70 9 26 ## 150 NA 145 13.2 77 9 27 ## 151 14 191 14.3 75 9 28 ## 152 18 131 8.0 76 9 29 ## 153 20 223 11.5 68 9 30 2.3.2 Discussion You can use either as.data.frame() or dplyr::collect() to do this. 2.4 Write a Parquet file You want to write Parquet files to disk. 2.4.1 Solution # Create table my_table &lt;- arrow_table(data.frame(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) # Write to Parquet write_parquet(my_table, &quot;my_table.parquet&quot;) 2.5 Read a Parquet file You want to read a Parquet file. 2.5.1 Solution parquet_tbl &lt;- read_parquet(&quot;my_table.parquet&quot;) parquet_tbl ## group score ## 1 A 99 ## 2 B 97 ## 3 C 99 As the argument as_data_frame was left set to its default value of TRUE, the file was read in as a data.frame object. class(parquet_tbl) ## [1] &quot;data.frame&quot; 2.5.2 Discussion If you set as_data_frame to FALSE, the file will be read in as an Arrow Table. my_table_arrow &lt;- read_parquet(&quot;my_table.parquet&quot;, as_data_frame = FALSE) my_table_arrow ## Table ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; ## ## See $metadata for additional Schema metadata class(my_table_arrow) ## [1] &quot;Table&quot; &quot;ArrowTabular&quot; &quot;ArrowObject&quot; &quot;R6&quot; 2.6 Read a Parquet file from S3 You want to read a Parquet file from S3. 2.6.1 Solution df &lt;- read_parquet(file = &quot;s3://ursa-labs-taxi-data/2019/06/data.parquet&quot;) 2.6.2 See also For more in-depth instructions, including how to work with S3 buckets which require authentication, you can find a guide to reading and writing to/from S3 buckets here: https://arrow.apache.org/docs/r/articles/fs.html. 2.7 Filter columns while reading a Parquet file You want to specify which columns to include when reading in a Parquet file. 2.7.1 Solution # Create table to read back in dist_time &lt;- arrow_table(data.frame(distance = c(12.2, 15.7, 14.2), time = c(43, 44, 40))) # Write to Parquet write_parquet(dist_time, &quot;dist_time.parquet&quot;) # Read in only the &quot;time&quot; column time_only &lt;- read_parquet(&quot;dist_time.parquet&quot;, col_select = &quot;time&quot;) time_only ## time ## 1 43 ## 2 44 ## 3 40 2.8 Write an IPC/Feather V2 file You want to read in a Feather file. 2.8.1 Solution my_table &lt;- arrow_table(data.frame(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) write_feather(my_table, &quot;my_table.arrow&quot;) 2.8.2 Discussion For legacy support, you can write data in the original Feather format by setting the version parameter to 1. # Create table my_table &lt;- arrow_table(data.frame(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) # Write to Feather format V1 write_feather(mtcars, &quot;my_table.feather&quot;, version = 1) 2.9 Read a Feather file You want to read a Feather file. 2.9.1 Solution my_feather_tbl &lt;- read_feather(&quot;my_table.arrow&quot;) 2.10 Write streaming IPC files You want to write to the IPC stream format. 2.10.1 Solution # Create table my_table &lt;- arrow_table( data.frame( group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99) ) ) # Write to IPC stream format write_ipc_stream(my_table, &quot;my_table.arrows&quot;) 2.11 Read streaming IPC files You want to read from the IPC stream format. 2.11.1 Solution my_ipc_stream &lt;- arrow::read_ipc_stream(&quot;my_table.arrows&quot;) 2.12 Read CSV files You want to write Arrow data to a CSV file. 2.12.1 Solution write_csv_arrow(cars, &quot;cars.csv&quot;) 2.13 Write CSV files You want to read a CSV file. 2.13.1 Solution my_csv &lt;- read_csv_arrow(&quot;cars.csv&quot;, as_data_frame = FALSE) 2.14 Read JSON files You want to read a JSON file. 2.14.1 Solution # Create a file to read back in tf &lt;- tempfile() writeLines(&#39; {&quot;country&quot;: &quot;United Kingdom&quot;, &quot;code&quot;: &quot;GB&quot;, &quot;long&quot;: -3.44, &quot;lat&quot;: 55.38} {&quot;country&quot;: &quot;France&quot;, &quot;code&quot;: &quot;FR&quot;, &quot;long&quot;: 2.21, &quot;lat&quot;: 46.23} {&quot;country&quot;: &quot;Germany&quot;, &quot;code&quot;: &quot;DE&quot;, &quot;long&quot;: 10.45, &quot;lat&quot;: 51.17} &#39;, tf, useBytes = TRUE) # Read in the data countries &lt;- read_json_arrow(tf, col_select = c(&quot;country&quot;, &quot;long&quot;, &quot;lat&quot;)) countries ## # A tibble: 3 × 3 ## country long lat ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 United Kingdom -3.44 55.4 ## 2 France 2.21 46.2 ## 3 Germany 10.4 51.2 2.15 Write partitioned data You want to save data to disk in partitions based on columns in the data. 2.15.1 Solution write_dataset(airquality, &quot;airquality_partitioned&quot;, partitioning = c(&quot;Month&quot;, &quot;Day&quot;)) list.files(&quot;airquality_partitioned&quot;) ## [1] &quot;Month=5&quot; &quot;Month=6&quot; &quot;Month=7&quot; &quot;Month=8&quot; &quot;Month=9&quot; As you can see, this has created folders based on the first partition variable supplied, Month. If you take a look in one of these folders, you will see that the data is then partitioned by the second partition variable, Day. list.files(&quot;airquality_partitioned/Month=5&quot;) ## [1] &quot;Day=1&quot; &quot;Day=10&quot; &quot;Day=11&quot; &quot;Day=12&quot; &quot;Day=13&quot; &quot;Day=14&quot; &quot;Day=15&quot; &quot;Day=16&quot; ## [9] &quot;Day=17&quot; &quot;Day=18&quot; &quot;Day=19&quot; &quot;Day=2&quot; &quot;Day=20&quot; &quot;Day=21&quot; &quot;Day=22&quot; &quot;Day=23&quot; ## [17] &quot;Day=24&quot; &quot;Day=25&quot; &quot;Day=26&quot; &quot;Day=27&quot; &quot;Day=28&quot; &quot;Day=29&quot; &quot;Day=3&quot; &quot;Day=30&quot; ## [25] &quot;Day=31&quot; &quot;Day=4&quot; &quot;Day=5&quot; &quot;Day=6&quot; &quot;Day=7&quot; &quot;Day=8&quot; &quot;Day=9&quot; Each of these folders contains 1 or more Parquet files containing the relevant partition of the data. list.files(&quot;airquality_partitioned/Month=5/Day=10&quot;) ## [1] &quot;part-0.parquet&quot; 2.16 Read partitioned data You want to read partitioned data. 2.16.1 Solution # Read data from directory air_data &lt;- open_dataset(&quot;airquality_partitioned&quot;) # View data air_data ## FileSystemDataset with 153 Parquet files ## Ozone: int32 ## Solar.R: int32 ## Wind: double ## Temp: int32 ## Month: int32 ## Day: int32 ## ## See $metadata for additional Schema metadata unlink(&quot;airquality_partitioned&quot;, recursive = TRUE) 2.17 Write compressed data You want to save a file, compressed with a specified compression algorithm. 2.17.1 Solution # Create a temporary directory td &lt;- tempfile() dir.create(td) # Write data compressed with the gzip algorithm instead of the default write_parquet(iris, file.path(td, &quot;iris.parquet&quot;), compression = &quot;gzip&quot;) 2.17.2 Discussion Note that write_parquet() by default already uses compression. See default_parquet_compression() to see what the default configured on your machine is. You can also supply the compression argument to write_dataset(), as long as the compression algorithm is compatible with the chosen format. # Create a temporary directory td &lt;- tempfile() dir.create(td) # Write dataset to file write_dataset(iris, path = td, compression = &quot;gzip&quot;) # View files in the directory list.files(td, recursive = TRUE) ## [1] &quot;part-0.parquet&quot; 2.17.3 See also Some formats write compressed data by default. For more information on the supported compression algorithms and default settings, see: ?write_parquet() ?write_feather() ?write_dataset() 2.18 Read compressed data You want to read in data which has been compressed. 2.18.1 Solution # Create a temporary directory td &lt;- tempfile() dir.create(td) # Write dataset which is to be read back in write_parquet(iris, file.path(td, &quot;iris.parquet&quot;), compression = &quot;gzip&quot;) # Read in data ds &lt;- read_parquet(file.path(td, &quot;iris.parquet&quot;)) %&gt;% collect() ds ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 17 5.4 3.9 1.3 0.4 setosa ## 18 5.1 3.5 1.4 0.3 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 20 5.1 3.8 1.5 0.3 setosa ## 21 5.4 3.4 1.7 0.2 setosa ## 22 5.1 3.7 1.5 0.4 setosa ## 23 4.6 3.6 1.0 0.2 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 25 4.8 3.4 1.9 0.2 setosa ## 26 5.0 3.0 1.6 0.2 setosa ## 27 5.0 3.4 1.6 0.4 setosa ## 28 5.2 3.5 1.5 0.2 setosa ## 29 5.2 3.4 1.4 0.2 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 31 4.8 3.1 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 33 5.2 4.1 1.5 0.1 setosa ## 34 5.5 4.2 1.4 0.2 setosa ## 35 4.9 3.1 1.5 0.2 setosa ## 36 5.0 3.2 1.2 0.2 setosa ## 37 5.5 3.5 1.3 0.2 setosa ## 38 4.9 3.6 1.4 0.1 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 40 5.1 3.4 1.5 0.2 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 43 4.4 3.2 1.3 0.2 setosa ## 44 5.0 3.5 1.6 0.6 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 47 5.1 3.8 1.6 0.2 setosa ## 48 4.6 3.2 1.4 0.2 setosa ## 49 5.3 3.7 1.5 0.2 setosa ## 50 5.0 3.3 1.4 0.2 setosa ## 51 7.0 3.2 4.7 1.4 versicolor ## 52 6.4 3.2 4.5 1.5 versicolor ## 53 6.9 3.1 4.9 1.5 versicolor ## 54 5.5 2.3 4.0 1.3 versicolor ## 55 6.5 2.8 4.6 1.5 versicolor ## 56 5.7 2.8 4.5 1.3 versicolor ## 57 6.3 3.3 4.7 1.6 versicolor ## 58 4.9 2.4 3.3 1.0 versicolor ## 59 6.6 2.9 4.6 1.3 versicolor ## 60 5.2 2.7 3.9 1.4 versicolor ## 61 5.0 2.0 3.5 1.0 versicolor ## 62 5.9 3.0 4.2 1.5 versicolor ## 63 6.0 2.2 4.0 1.0 versicolor ## 64 6.1 2.9 4.7 1.4 versicolor ## 65 5.6 2.9 3.6 1.3 versicolor ## 66 6.7 3.1 4.4 1.4 versicolor ## 67 5.6 3.0 4.5 1.5 versicolor ## 68 5.8 2.7 4.1 1.0 versicolor ## 69 6.2 2.2 4.5 1.5 versicolor ## 70 5.6 2.5 3.9 1.1 versicolor ## 71 5.9 3.2 4.8 1.8 versicolor ## 72 6.1 2.8 4.0 1.3 versicolor ## 73 6.3 2.5 4.9 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 75 6.4 2.9 4.3 1.3 versicolor ## 76 6.6 3.0 4.4 1.4 versicolor ## 77 6.8 2.8 4.8 1.4 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 79 6.0 2.9 4.5 1.5 versicolor ## 80 5.7 2.6 3.5 1.0 versicolor ## 81 5.5 2.4 3.8 1.1 versicolor ## 82 5.5 2.4 3.7 1.0 versicolor ## 83 5.8 2.7 3.9 1.2 versicolor ## 84 6.0 2.7 5.1 1.6 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 86 6.0 3.4 4.5 1.6 versicolor ## 87 6.7 3.1 4.7 1.5 versicolor ## 88 6.3 2.3 4.4 1.3 versicolor ## 89 5.6 3.0 4.1 1.3 versicolor ## 90 5.5 2.5 4.0 1.3 versicolor ## 91 5.5 2.6 4.4 1.2 versicolor ## 92 6.1 3.0 4.6 1.4 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 94 5.0 2.3 3.3 1.0 versicolor ## 95 5.6 2.7 4.2 1.3 versicolor ## 96 5.7 3.0 4.2 1.2 versicolor ## 97 5.7 2.9 4.2 1.3 versicolor ## 98 6.2 2.9 4.3 1.3 versicolor ## 99 5.1 2.5 3.0 1.1 versicolor ## 100 5.7 2.8 4.1 1.3 versicolor ## 101 6.3 3.3 6.0 2.5 virginica ## 102 5.8 2.7 5.1 1.9 virginica ## 103 7.1 3.0 5.9 2.1 virginica ## 104 6.3 2.9 5.6 1.8 virginica ## 105 6.5 3.0 5.8 2.2 virginica ## 106 7.6 3.0 6.6 2.1 virginica ## 107 4.9 2.5 4.5 1.7 virginica ## 108 7.3 2.9 6.3 1.8 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 110 7.2 3.6 6.1 2.5 virginica ## 111 6.5 3.2 5.1 2.0 virginica ## 112 6.4 2.7 5.3 1.9 virginica ## 113 6.8 3.0 5.5 2.1 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 115 5.8 2.8 5.1 2.4 virginica ## 116 6.4 3.2 5.3 2.3 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 118 7.7 3.8 6.7 2.2 virginica ## 119 7.7 2.6 6.9 2.3 virginica ## 120 6.0 2.2 5.0 1.5 virginica ## 121 6.9 3.2 5.7 2.3 virginica ## 122 5.6 2.8 4.9 2.0 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 124 6.3 2.7 4.9 1.8 virginica ## 125 6.7 3.3 5.7 2.1 virginica ## 126 7.2 3.2 6.0 1.8 virginica ## 127 6.2 2.8 4.8 1.8 virginica ## 128 6.1 3.0 4.9 1.8 virginica ## 129 6.4 2.8 5.6 2.1 virginica ## 130 7.2 3.0 5.8 1.6 virginica ## 131 7.4 2.8 6.1 1.9 virginica ## 132 7.9 3.8 6.4 2.0 virginica ## 133 6.4 2.8 5.6 2.2 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 virginica ## 136 7.7 3.0 6.1 2.3 virginica ## 137 6.3 3.4 5.6 2.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica ## 139 6.0 3.0 4.8 1.8 virginica ## 140 6.9 3.1 5.4 2.1 virginica ## 141 6.7 3.1 5.6 2.4 virginica ## 142 6.9 3.1 5.1 2.3 virginica ## 143 5.8 2.7 5.1 1.9 virginica ## 144 6.8 3.2 5.9 2.3 virginica ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica 2.18.2 Discussion Note that Arrow automatically detects the compression and you do not have to supply it in the call to open_dataset() or the read_*() functions. Although the CSV format does not support compression itself, Arrow supports reading in CSV data which has been compressed, if the file extension is .gz. # Create a temporary directory td &lt;- tempfile() dir.create(td) # Write dataset which is to be read back in write.csv(iris, gzfile(file.path(td, &quot;iris.csv.gz&quot;)), row.names = FALSE, quote = FALSE) # Read in data ds &lt;- open_dataset(td, format = &quot;csv&quot;) %&gt;% collect() ds ## # A tibble: 150 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows "],["creating-arrow-objects.html", "3 Creating Arrow Objects 3.1 Create an Arrow Array from an R object 3.2 Create a Arrow Table from an R object 3.3 View the contents of an Arrow Table or RecordBatch 3.4 Manually create a RecordBatch from an R object.", " 3 Creating Arrow Objects 3.1 Create an Arrow Array from an R object You want to convert an existing vector in R to an Arrow Array object. 3.1.1 Solution # Create an example vector score = c(99, 97, 99) # Convert to Arrow Array score_array &lt;- Array$create(score) # View Array score_array ## Array ## &lt;double&gt; ## [ ## 99, ## 97, ## 99 ## ] 3.2 Create a Arrow Table from an R object You want to convert an existing data frame in R to an Arrow Table object. 3.2.1 Solution # Create an example data frame my_tibble &lt;- tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99)) # Convert to Arrow Table my_table &lt;- arrow_table(my_tibble) # View table my_table ## Table ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; 3.3 View the contents of an Arrow Table or RecordBatch You want to view the contents of an Arrow Table or RecordBatch. 3.3.1 Solution # View Table dplyr::collect(my_table) ## # A tibble: 3 × 2 ## group score ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 99 ## 2 B 97 ## 3 C 99 3.4 Manually create a RecordBatch from an R object. You want to convert an existing data frame in R to an Arrow RecordBatch object. 3.4.1 Solution # Create an example data frame my_tibble &lt;- tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99)) # Convert to Arrow RecordBatch my_record_batch &lt;- record_batch(my_tibble) # View RecordBatch my_record_batch ## RecordBatch ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; "],["defining-data-types.html", "4 Defining Data Types 4.1 Introduction 4.2 Update data type of an existing Arrow Array 4.3 Update data type of a field in an existing Arrow Table 4.4 Specify data types when creating an Arrow table from an R object 4.5 Specify data types when reading in files", " 4 Defining Data Types 4.1 Introduction As discussed in previous chapters, Arrow automatically infers the most appropriate data type when reading in data or converting R objects to Arrow objects. However, you might want to manually tell Arrow which data types to use, for example, to ensure interoperability with databases and data warehouse systems. This chapter includes recipes for: changing the data types of existing Arrow objects defining data types during the process of creating Arrow objects A table showing the default mappings between R and Arrow data types can be found in R data type to Arrow data type mappings. A table containing Arrow data types, and their R equivalents can be found in Arrow data type to R data type mapping. 4.2 Update data type of an existing Arrow Array You want to change the data type of an existing Arrow Array. 4.2.1 Solution # Create an Array to cast integer_arr &lt;- Array$create(1:5) # Cast to an unsigned int8 type uint_arr &lt;- integer_arr$cast(target_type = uint8()) uint_arr ## Array ## &lt;uint8&gt; ## [ ## 1, ## 2, ## 3, ## 4, ## 5 ## ] 4.2.2 Discussion There are some data types which are not compatible with each other. Errors will occur if you try to cast between incompatible data types. int_arr &lt;- Array$create(1:5) int_arr$cast(target_type = binary()) ## Error: NotImplemented: Unsupported cast from int32 to binary using function cast_binary 4.3 Update data type of a field in an existing Arrow Table You want to change the type of one or more fields in an existing Arrow Table. 4.3.1 Solution # Set up a tibble to use in this example oscars &lt;- tibble::tibble( actor = c(&quot;Katharine Hepburn&quot;, &quot;Meryl Streep&quot;, &quot;Jack Nicholson&quot;), num_awards = c(4, 3, 3) ) # Convert tibble to an Arrow table oscars_arrow &lt;- arrow_table(oscars) # The default mapping from numeric column &quot;num_awards&quot; is to a double oscars_arrow ## Table ## 3 rows x 2 columns ## $actor &lt;string&gt; ## $num_awards &lt;double&gt; # Set up schema with &quot;num_awards&quot; as integer oscars_schema &lt;- schema(actor = string(), num_awards = int16()) # Cast to an int16 oscars_arrow_int &lt;- oscars_arrow$cast(target_schema = oscars_schema) oscars_arrow_int ## Table ## 3 rows x 2 columns ## $actor &lt;string&gt; ## $num_awards &lt;int16&gt; 4.3.2 Discussion There are some Arrow data types which do not have any R equivalent. Attempting to cast to these data types or using a schema which contains them will result in an error. # Set up a tibble to use in this example oscars &lt;- tibble::tibble( actor = c(&quot;Katharine Hepburn&quot;, &quot;Meryl Streep&quot;, &quot;Jack Nicholson&quot;), num_awards = c(4, 3, 3) ) # Convert tibble to an Arrow table oscars_arrow &lt;- arrow_table(oscars) # Set up schema with &quot;num_awards&quot; as float16 which doesn&#39;t have an R equivalent oscars_schema_invalid &lt;- schema(actor = string(), num_awards = float16()) # The default mapping from numeric column &quot;num_awards&quot; is to a double oscars_arrow$cast(target_schema = oscars_schema_invalid) ## Error: NotImplemented: Unsupported cast from double to halffloat using function cast_half_float 4.4 Specify data types when creating an Arrow table from an R object You want to manually specify Arrow data types when converting an object from a data frame to an Arrow object. 4.4.1 Solution # Set up a tibble to use in this example oscars &lt;- tibble::tibble( actor = c(&quot;Katharine Hepburn&quot;, &quot;Meryl Streep&quot;, &quot;Jack Nicholson&quot;), num_awards = c(4, 3, 3) ) # Set up schema with &quot;num_awards&quot; as integer oscars_schema &lt;- schema(actor = string(), num_awards = int16()) # create arrow Table containing data and schema oscars_data_arrow &lt;- arrow_table(oscars, schema = oscars_schema) oscars_data_arrow ## Table ## 3 rows x 2 columns ## $actor &lt;string&gt; ## $num_awards &lt;int16&gt; 4.5 Specify data types when reading in files You want to manually specify Arrow data types when reading in files. 4.5.1 Solution # Set up a tibble to use in this example oscars &lt;- tibble::tibble( actor = c(&quot;Katharine Hepburn&quot;, &quot;Meryl Streep&quot;, &quot;Jack Nicholson&quot;), num_awards = c(4, 3, 3) ) # write dataset to disk write_dataset(oscars, path = &quot;oscars_data&quot;) # Set up schema with &quot;num_awards&quot; as integer oscars_schema &lt;- schema(actor = string(), num_awards = int16()) # read the dataset in, using the schema instead of inferring the type automatically oscars_dataset_arrow &lt;- open_dataset(&quot;oscars_data&quot;, schema = oscars_schema) oscars_dataset_arrow ## FileSystemDataset with 1 Parquet file ## actor: string ## num_awards: int16 "],["manipulating-data---arrays.html", "5 Manipulating Data - Arrays 5.1 Introduction 5.2 Filter by values matching a predicate or mask 5.3 Compute Mean/Min/Max, etc value of an Array 5.4 Count occurrences of elements in an Array 5.5 Apply arithmetic functions to Arrays. 5.6 Call Arrow compute functions directly on Arrays", " 5 Manipulating Data - Arrays 5.1 Introduction An Arrow Array is roughly equivalent to an R vector - it can be used to represent a single column of data, with all values having the same data type. A number of base R functions which have S3 generic methods have been implemented to work on Arrow Arrays; for example mean, min, and max. 5.2 Filter by values matching a predicate or mask You want to search for values in an Array that match a predicate condition. 5.2.1 Solution my_values &lt;- Array$create(c(1:5, NA)) my_values[my_values &gt; 3] ## Array ## &lt;int32&gt; ## [ ## 4, ## 5, ## null ## ] 5.2.2 Discussion You can refer to items in an Array using the square brackets [] like you can an R vector. 5.3 Compute Mean/Min/Max, etc value of an Array You want to calculate the mean, minimum, or maximum of values in an array. 5.3.1 Solution my_values &lt;- Array$create(c(1:5, NA)) mean(my_values, na.rm = TRUE) ## Scalar ## 3 5.3.2 Discussion Many base R generic functions such as mean(), min(), and max() have been mapped to their Arrow equivalents, and so can be called on Arrow Array objects in the same way. They will return Arrow objects themselves. If you want to use an R function which does not have an Arrow mapping, you can use as.vector() to convert Arrow objects to base R vectors. arrow_array &lt;- Array$create(1:100) # get Tukey&#39;s five-number summary fivenum(as.vector(arrow_array)) ## [1] 1.0 25.5 50.5 75.5 100.0 You can tell if a function is a standard S3 generic function by looking at the body of the function - S3 generic functions call UseMethod() to determine the appropriate version of that function to use for the object. mean ## function (x, ...) ## UseMethod(&quot;mean&quot;) ## &lt;bytecode: 0x55cfa93a7c98&gt; ## &lt;environment: namespace:base&gt; You can also use isS3stdGeneric() to determine if a function is an S3 generic. isS3stdGeneric(&quot;mean&quot;) ## mean ## TRUE If you find an S3 generic function which isn’t implemented for Arrow objects but you would like to be able to use, please open an issue on the project JIRA. 5.4 Count occurrences of elements in an Array You want to count repeated values in an Array. 5.4.1 Solution repeated_vals &lt;- Array$create(c(1, 1, 2, 3, 3, 3, 3, 3)) value_counts(repeated_vals) ## StructArray ## &lt;struct&lt;values: double, counts: int64&gt;&gt; ## -- is_valid: all not null ## -- child 0 type: double ## [ ## 1, ## 2, ## 3 ## ] ## -- child 1 type: int64 ## [ ## 2, ## 1, ## 5 ## ] 5.4.2 Discussion Some functions in the Arrow R package do not have base R equivalents. In other cases, the base R equivalents are not generic functions so they cannot be called directly on Arrow Array objects. For example, the value_counts() function in the Arrow R package is loosely equivalent to the base R function table(), which is not a generic function. 5.5 Apply arithmetic functions to Arrays. You want to use the various arithmetic operators on Array objects. 5.5.1 Solution num_array &lt;- Array$create(1:10) num_array + 10 ## Array ## &lt;double&gt; ## [ ## 11, ## 12, ## 13, ## 14, ## 15, ## 16, ## 17, ## 18, ## 19, ## 20 ## ] 5.5.2 Discussion You will get the same result if you pass in the value you’re adding as an Arrow object. num_array + Scalar$create(10) ## Array ## &lt;double&gt; ## [ ## 11, ## 12, ## 13, ## 14, ## 15, ## 16, ## 17, ## 18, ## 19, ## 20 ## ] 5.6 Call Arrow compute functions directly on Arrays You want to call an Arrow compute function directly on an Array. 5.6.1 Solution first_100_numbers &lt;- Array$create(1:100) # Calculate the variance of 1 to 100, setting the delta degrees of freedom to 0. call_function(&quot;variance&quot;, first_100_numbers, options = list(ddof = 0)) ## Scalar ## 833.25 5.6.2 Discussion You can use call_function() to call Arrow compute functions directly on Scalar, Array, and ChunkedArray objects. The returned object will be an Arrow object. 5.6.3 See also For a more in-depth discussion of Arrow compute functions, see the section on using arrow functions in dplyr verbs in arrow "],["manipulating-data---tables.html", "6 Manipulating Data - Tables 6.1 Introduction 6.2 Use dplyr verbs in arrow 6.3 Use R functions in dplyr verbs in arrow 6.4 Use arrow functions in dplyr verbs in arrow", " 6 Manipulating Data - Tables 6.1 Introduction One of the aims of the Arrow project is to reduce duplication between different data frame implementations. The underlying implementation of a data frame is a conceptually different thing to the code that you run to work with it - the API. You may have seen this before in packages like dbplyr which allow you to use the dplyr API to interact with SQL databases. The arrow package has been written so that the underlying Arrow table-like objects can be manipulated via use of the dplyr API via the dplyr verbs. For example, here’s a short pipeline of data manipulation which uses dplyr exclusively: library(dplyr) starwars %&gt;% filter(species == &quot;Human&quot;) %&gt;% mutate(height_ft = height/30.48) %&gt;% select(name, height_ft) ## # A tibble: 35 × 2 ## name height_ft ## &lt;chr&gt; &lt;dbl&gt; ## 1 Luke Skywalker 5.64 ## 2 Darth Vader 6.63 ## 3 Leia Organa 4.92 ## 4 Owen Lars 5.84 ## 5 Beru Whitesun lars 5.41 ## 6 Biggs Darklighter 6.00 ## 7 Obi-Wan Kenobi 5.97 ## 8 Anakin Skywalker 6.17 ## 9 Wilhuff Tarkin 5.91 ## 10 Han Solo 5.91 ## # … with 25 more rows And the same results as using arrow with dplyr syntax: arrow_table(starwars) %&gt;% filter(species == &quot;Human&quot;) %&gt;% mutate(height_ft = height/30.48) %&gt;% select(name, height_ft) %&gt;% collect() ## # A tibble: 35 × 2 ## name height_ft ## &lt;chr&gt; &lt;dbl&gt; ## 1 Luke Skywalker 5.64 ## 2 Darth Vader 6.63 ## 3 Leia Organa 4.92 ## 4 Owen Lars 5.84 ## 5 Beru Whitesun lars 5.41 ## 6 Biggs Darklighter 6.00 ## 7 Obi-Wan Kenobi 5.97 ## 8 Anakin Skywalker 6.17 ## 9 Wilhuff Tarkin 5.91 ## 10 Han Solo 5.91 ## # … with 25 more rows You’ll notice we’ve used collect() in the Arrow pipeline above. That’s because one of the ways in which arrow is efficient is that it works out the instructions for the calculations it needs to perform (expressions) and only runs them using arrow once you actually pull the data into your R session. This means instead of doing lots of separate operations, it does them all at once in a more optimised way, lazy evaluation. It also means that you are able to manipulate data that is larger than you can fit into memory on the machine you’re running your code on, if you only pull data into R when you have selected the desired subset, or when using functions which can operate on chunks of data. You can also have data which is split across multiple files. For example, you might have files which are stored in multiple Parquet or Feather files, partitioned across different directories. You can open multi-file datasets using open_dataset() as discussed in a previous chapter, and then manipulate this data using arrow before even reading any of it into R. 6.2 Use dplyr verbs in arrow You want to use a dplyr verb in arrow. 6.2.1 Solution library(dplyr) arrow_table(starwars) %&gt;% filter(species == &quot;Human&quot;, homeworld == &quot;Tatooine&quot;) %&gt;% collect() ## # A tibble: 8 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sky… 172 77 blond fair blue 19 male mascu… ## 2 Darth Va… 202 136 none white yellow 41.9 male mascu… ## 3 Owen Lars 178 120 brown, gr… light blue 52 male mascu… ## 4 Beru Whi… 165 75 brown light blue 47 fema… femin… ## 5 Biggs Da… 183 84 black light brown 24 male mascu… ## 6 Anakin S… 188 84 blond fair blue 41.9 male mascu… ## 7 Shmi Sky… 163 NA black fair brown 72 fema… femin… ## 8 Cliegg L… 183 NA brown fair blue 82 male mascu… ## # … with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&lt;character&gt;&gt;, vehicles &lt;list&lt;character&gt;&gt;, ## # starships &lt;list&lt;character&gt;&gt; 6.2.2 Discussion You can use most of the dplyr verbs directly from arrow. 6.2.3 See also You can find examples of the various dplyr verbs in “Introduction to dplyr” - run vignette(\"dplyr\", package = \"dplyr\") or view on the pkgdown site. You can see more information about using arrow_table() to create Arrow Tables and collect() to view them as R data frames in Creating Arrow Objects. 6.3 Use R functions in dplyr verbs in arrow You want to use an R function inside a dplyr verb in arrow. 6.3.1 Solution arrow_table(starwars) %&gt;% filter(str_detect(name, &quot;Darth&quot;)) %&gt;% collect() ## # A tibble: 2 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Darth Va… 202 136 none white yellow 41.9 male mascu… ## 2 Darth Ma… 175 80 none red yellow 54 male mascu… ## # … with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&lt;character&gt;&gt;, vehicles &lt;list&lt;character&gt;&gt;, ## # starships &lt;list&lt;character&gt;&gt; 6.3.2 Discussion The arrow package allows you to use dplyr verbs containing expressions which include base R and many tidyverse functions, but call Arrow functions under the hood. If you find any base R or tidyverse functions which you would like to see a mapping of in arrow, please open an issue on the project JIRA. The following packages (amongst some from others) have had many function bindings/mappings written in arrow: lubridate stringr dplyr If you try to call a function which does not have arrow mapping, the data will be pulled back into R, and you will see a warning message. library(stringr) arrow_table(starwars) %&gt;% mutate(name_split = str_split_fixed(name, &quot; &quot;, 2)) %&gt;% collect() ## Warning: Expression str_split_fixed(name, &quot; &quot;, 2) not supported in Arrow; ## pulling data into R ## # A tibble: 87 × 15 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… 172 77 blond fair blue 19 male mascu… ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none mascu… ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 4 Darth V… 202 136 none white yellow 41.9 male mascu… ## 5 Leia Or… 150 49 brown light brown 19 fema… femin… ## 6 Owen La… 178 120 brown, gr… light blue 52 male mascu… ## 7 Beru Wh… 165 75 brown light blue 47 fema… femin… ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 9 Biggs D… 183 84 black light brown 24 male mascu… ## 10 Obi-Wan… 182 77 auburn, w… fair blue-gray 57 male mascu… ## # … with 77 more rows, and 6 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&lt;character&gt;&gt;, vehicles &lt;list&lt;character&gt;&gt;, ## # starships &lt;list&lt;character&gt;&gt;, name_split &lt;chr[,2]&gt; It should be noted that to work with functions which do have mappings, you must refer to them by their function names. If you use the package::function() syntax, this will result in a warning about the data being pulled back into R before the output is calculated. arrow_table(starwars) %&gt;% select(name) %&gt;% mutate(name_lower = stringr::str_to_lower(name)) %&gt;% head() %&gt;% collect() ## Warning: Expression stringr::str_to_lower(name) not supported in Arrow; pulling ## data into R ## # A tibble: 6 × 2 ## name name_lower ## &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker luke skywalker ## 2 C-3PO c-3po ## 3 R2-D2 r2-d2 ## 4 Darth Vader darth vader ## 5 Leia Organa leia organa ## 6 Owen Lars owen lars 6.4 Use arrow functions in dplyr verbs in arrow You want to use a function which is implemented in Arrow’s C++ library but either: it doesn’t have a mapping to a base R or tidyverse equivalent, or it has a mapping but nevertheless you want to call the C++ function directly 6.4.1 Solution arrow_table(starwars) %&gt;% select(name) %&gt;% mutate(padded_name = arrow_ascii_lpad(name, options = list(width = 10, padding = &quot;*&quot;))) %&gt;% collect() ## # A tibble: 87 × 2 ## name padded_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker Luke Skywalker ## 2 C-3PO *****C-3PO ## 3 R2-D2 *****R2-D2 ## 4 Darth Vader Darth Vader ## 5 Leia Organa Leia Organa ## 6 Owen Lars *Owen Lars ## 7 Beru Whitesun lars Beru Whitesun lars ## 8 R5-D4 *****R5-D4 ## 9 Biggs Darklighter Biggs Darklighter ## 10 Obi-Wan Kenobi Obi-Wan Kenobi ## # … with 77 more rows 6.4.2 Discussion The vast majority of Arrow C++ compute functions have been mapped to their base R or tidyverse equivalents, and we strongly recommend that you use these mappings where possible, as the original functions are well documented and the mapped versions have been tested to ensure the results returned are as expected. However, there may be circumstances in which you might want to use a compute function from the Arrow C++ library which does not have a base R or tidyverse equivalent. You can find documentation of Arrow C++ compute functions in the C++ documention. This documentation lists all available compute functions, any associated options classes they need, and the valid data types that they can be used with. You can list all available Arrow compute functions from R by calling list_compute_functions(). list_compute_functions() ## [1] &quot;abs&quot; &quot;abs_checked&quot; ## [3] &quot;acos&quot; &quot;acos_checked&quot; ## [5] &quot;add&quot; &quot;add_checked&quot; ## [7] &quot;all&quot; &quot;and&quot; ## [9] &quot;and_kleene&quot; &quot;and_not&quot; ## [11] &quot;and_not_kleene&quot; &quot;any&quot; ## [13] &quot;approximate_median&quot; &quot;array_filter&quot; ## [15] &quot;array_sort_indices&quot; &quot;array_take&quot; ## [17] &quot;ascii_capitalize&quot; &quot;ascii_center&quot; ## [19] &quot;ascii_is_alnum&quot; &quot;ascii_is_alpha&quot; ## [21] &quot;ascii_is_decimal&quot; &quot;ascii_is_lower&quot; ## [23] &quot;ascii_is_printable&quot; &quot;ascii_is_space&quot; ## [25] &quot;ascii_is_title&quot; &quot;ascii_is_upper&quot; ## [27] &quot;ascii_lower&quot; &quot;ascii_lpad&quot; ## [29] &quot;ascii_ltrim&quot; &quot;ascii_ltrim_whitespace&quot; ## [31] &quot;ascii_reverse&quot; &quot;ascii_rpad&quot; ## [33] &quot;ascii_rtrim&quot; &quot;ascii_rtrim_whitespace&quot; ## [35] &quot;ascii_split_whitespace&quot; &quot;ascii_swapcase&quot; ## [37] &quot;ascii_title&quot; &quot;ascii_trim&quot; ## [39] &quot;ascii_trim_whitespace&quot; &quot;ascii_upper&quot; ## [41] &quot;asin&quot; &quot;asin_checked&quot; ## [43] &quot;assume_timezone&quot; &quot;atan&quot; ## [45] &quot;atan2&quot; &quot;binary_join&quot; ## [47] &quot;binary_join_element_wise&quot; &quot;binary_length&quot; ## [49] &quot;binary_repeat&quot; &quot;binary_replace_slice&quot; ## [51] &quot;binary_reverse&quot; &quot;bit_wise_and&quot; ## [53] &quot;bit_wise_not&quot; &quot;bit_wise_or&quot; ## [55] &quot;bit_wise_xor&quot; &quot;case_when&quot; ## [57] &quot;cast&quot; &quot;ceil&quot; ## [59] &quot;ceil_temporal&quot; &quot;choose&quot; ## [61] &quot;coalesce&quot; &quot;cos&quot; ## [63] &quot;cos_checked&quot; &quot;count&quot; ## [65] &quot;count_distinct&quot; &quot;count_substring&quot; ## [67] &quot;count_substring_regex&quot; &quot;day&quot; ## [69] &quot;day_of_week&quot; &quot;day_of_year&quot; ## [71] &quot;day_time_interval_between&quot; &quot;days_between&quot; ## [73] &quot;dictionary_encode&quot; &quot;divide&quot; ## [75] &quot;divide_checked&quot; &quot;drop_null&quot; ## [77] &quot;ends_with&quot; &quot;equal&quot; ## [79] &quot;extract_regex&quot; &quot;fill_null_backward&quot; ## [81] &quot;fill_null_forward&quot; &quot;filter&quot; ## [83] &quot;find_substring&quot; &quot;find_substring_regex&quot; ## [85] &quot;floor&quot; &quot;floor_temporal&quot; ## [87] &quot;greater&quot; &quot;greater_equal&quot; ## [89] &quot;hour&quot; &quot;hours_between&quot; ## [91] &quot;if_else&quot; &quot;index&quot; ## [93] &quot;index_in&quot; &quot;index_in_meta_binary&quot; ## [95] &quot;indices_nonzero&quot; &quot;invert&quot; ## [97] &quot;is_finite&quot; &quot;is_in&quot; ## [99] &quot;is_in_meta_binary&quot; &quot;is_inf&quot; ## [101] &quot;is_nan&quot; &quot;is_null&quot; ## [103] &quot;is_valid&quot; &quot;iso_calendar&quot; ## [105] &quot;iso_week&quot; &quot;iso_year&quot; ## [107] &quot;less&quot; &quot;less_equal&quot; ## [109] &quot;list_element&quot; &quot;list_flatten&quot; ## [111] &quot;list_parent_indices&quot; &quot;list_value_length&quot; ## [113] &quot;ln&quot; &quot;ln_checked&quot; ## [115] &quot;log10&quot; &quot;log10_checked&quot; ## [117] &quot;log1p&quot; &quot;log1p_checked&quot; ## [119] &quot;log2&quot; &quot;log2_checked&quot; ## [121] &quot;logb&quot; &quot;logb_checked&quot; ## [123] &quot;make_struct&quot; &quot;match_like&quot; ## [125] &quot;match_substring&quot; &quot;match_substring_regex&quot; ## [127] &quot;max&quot; &quot;max_element_wise&quot; ## [129] &quot;mean&quot; &quot;microsecond&quot; ## [131] &quot;microseconds_between&quot; &quot;millisecond&quot; ## [133] &quot;milliseconds_between&quot; &quot;min&quot; ## [135] &quot;min_element_wise&quot; &quot;min_max&quot; ## [137] &quot;minute&quot; &quot;minutes_between&quot; ## [139] &quot;mode&quot; &quot;month&quot; ## [141] &quot;month_day_nano_interval_between&quot; &quot;month_interval_between&quot; ## [143] &quot;multiply&quot; &quot;multiply_checked&quot; ## [145] &quot;nanosecond&quot; &quot;nanoseconds_between&quot; ## [147] &quot;negate&quot; &quot;negate_checked&quot; ## [149] &quot;not_equal&quot; &quot;or&quot; ## [151] &quot;or_kleene&quot; &quot;partition_nth_indices&quot; ## [153] &quot;power&quot; &quot;power_checked&quot; ## [155] &quot;product&quot; &quot;quantile&quot; ## [157] &quot;quarter&quot; &quot;quarters_between&quot; ## [159] &quot;random&quot; &quot;replace_substring&quot; ## [161] &quot;replace_substring_regex&quot; &quot;replace_with_mask&quot; ## [163] &quot;round&quot; &quot;round_temporal&quot; ## [165] &quot;round_to_multiple&quot; &quot;second&quot; ## [167] &quot;seconds_between&quot; &quot;select_k_unstable&quot; ## [169] &quot;shift_left&quot; &quot;shift_left_checked&quot; ## [171] &quot;shift_right&quot; &quot;shift_right_checked&quot; ## [173] &quot;sign&quot; &quot;sin&quot; ## [175] &quot;sin_checked&quot; &quot;sort_indices&quot; ## [177] &quot;split_pattern&quot; &quot;split_pattern_regex&quot; ## [179] &quot;starts_with&quot; &quot;stddev&quot; ## [181] &quot;strftime&quot; &quot;string_is_ascii&quot; ## [183] &quot;strptime&quot; &quot;struct_field&quot; ## [185] &quot;subsecond&quot; &quot;subtract&quot; ## [187] &quot;subtract_checked&quot; &quot;sum&quot; ## [189] &quot;take&quot; &quot;tan&quot; ## [191] &quot;tan_checked&quot; &quot;tdigest&quot; ## [193] &quot;trunc&quot; &quot;unique&quot; ## [195] &quot;us_week&quot; &quot;utf8_capitalize&quot; ## [197] &quot;utf8_center&quot; &quot;utf8_is_alnum&quot; ## [199] &quot;utf8_is_alpha&quot; &quot;utf8_is_decimal&quot; ## [201] &quot;utf8_is_digit&quot; &quot;utf8_is_lower&quot; ## [203] &quot;utf8_is_numeric&quot; &quot;utf8_is_printable&quot; ## [205] &quot;utf8_is_space&quot; &quot;utf8_is_title&quot; ## [207] &quot;utf8_is_upper&quot; &quot;utf8_length&quot; ## [209] &quot;utf8_lower&quot; &quot;utf8_lpad&quot; ## [211] &quot;utf8_ltrim&quot; &quot;utf8_ltrim_whitespace&quot; ## [213] &quot;utf8_normalize&quot; &quot;utf8_replace_slice&quot; ## [215] &quot;utf8_reverse&quot; &quot;utf8_rpad&quot; ## [217] &quot;utf8_rtrim&quot; &quot;utf8_rtrim_whitespace&quot; ## [219] &quot;utf8_slice_codeunits&quot; &quot;utf8_split_whitespace&quot; ## [221] &quot;utf8_swapcase&quot; &quot;utf8_title&quot; ## [223] &quot;utf8_trim&quot; &quot;utf8_trim_whitespace&quot; ## [225] &quot;utf8_upper&quot; &quot;value_counts&quot; ## [227] &quot;variance&quot; &quot;week&quot; ## [229] &quot;weeks_between&quot; &quot;xor&quot; ## [231] &quot;year&quot; &quot;year_month_day&quot; ## [233] &quot;years_between&quot; The majority of functions here have been mapped to their base R or tidyverse equivalent and can be called within a dplyr query as usual. For functions which don’t have a base R or tidyverse equivalent, or you want to supply custom options, you can call them by prefixing their name with “arrow_”. For example, base R’s is.na() function is the equivalent of the Arrow C++ compute function is_null() with the option nan_is_null set to TRUE. A mapping between these functions (with nan_is_null set to TRUE) has been created in arrow. demo_df &lt;- data.frame(x = c(1, 2, 3, NA, NaN)) arrow_table(demo_df) %&gt;% mutate(y = is.na(x)) %&gt;% collect() ## x y ## 1 1 FALSE ## 2 2 FALSE ## 3 3 FALSE ## 4 NA TRUE ## 5 NaN TRUE If you want to call Arrow’s is_null() function but with nan_is_null set to FALSE (so it returns TRUE when a value being examined is NA but FALSE when the value being examined is NaN), you must call is_null() directly and specify the option nan_is_null = FALSE. arrow_table(demo_df) %&gt;% mutate(y = arrow_is_null(x, options = list(nan_is_null = FALSE))) %&gt;% collect() ## x y ## 1 1 FALSE ## 2 2 FALSE ## 3 3 FALSE ## 4 NA TRUE ## 5 NaN FALSE 6.4.2.1 Compute functions with options Although not all Arrow C++ compute functions require options to be specified, most do. For these functions to work in R, they must be linked up with the appropriate libarrow options C++ class via the R package’s C++ code. At the time of writing, all compute functions available in the development version of the arrow R package had been associated with their options classes. However, as the Arrow C++ library’s functionality extends, compute functions may be added which do not yet have an R binding. If you find a C++ compute function which you wish to use from the R package, please open an issue on the project JIRA. "],["using-pyarrow-from-r.html", "7 Using PyArrow from R 7.1 Introduction 7.2 Create an Arrow object using PyArrow in R 7.3 Call a PyArrow function from R", " 7 Using PyArrow from R 7.1 Introduction For more information on using setting up and installing PyArrow to use in R, see the “Apache Arrow in Python and R with reticulate” vignette. 7.2 Create an Arrow object using PyArrow in R You want to use PyArrow to create an Arrow object in an R session. 7.2.1 Solution library(reticulate) pa &lt;- import(&quot;pyarrow&quot;) pyarrow_scalar &lt;- pa$scalar(42) pyarrow_scalar ## 42.0 7.3 Call a PyArrow function from R You want to call a PyArrow function from your R session. 7.3.1 Solution table_1 &lt;- arrow_table(mtcars[1:5,]) table_2 &lt;- arrow_table(mtcars[11:15,]) pa$concat_tables(tables = list(table_1, table_2)) %&gt;% collect() ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## 6 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## 7 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## 8 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## 9 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## 10 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 "],["flight.html", "8 Flight 8.1 Introduction 8.2 Connect to a Flight server 8.3 Send data to a Flight server 8.4 Check what resources exist on a Flight server 8.5 Retrieve data from a Flight server", " 8 Flight 8.1 Introduction Flight is a general-purpose client-server framework for high performance transport of large datasets over network interfaces, built as part of the Apache Arrow project. Flight allows for highly efficient data transfer as it: removes the need for serialization during data transfer allows for parallel data streaming is highly optimized to take advantage of Arrow’s columnar format. The arrow package provides methods for connecting to Flight RPC servers to send and receive data. It should be noted that the Flight implementation in the R package depends on PyArrow which is called via reticulate. This is quite different from the other capabilities in the R package, nearly all of which are all implemented directly. 8.2 Connect to a Flight server You want to connect to a Flight server running on a specified host and port. 8.2.1 Solution local_client &lt;- flight_connect(host = &quot;127.0.0.1&quot;, port = 8089) 8.2.2 See also For an example of how to set up a Flight server from R, see the Flight vignette. 8.3 Send data to a Flight server You want to send data that you have in memory to a Flight server 8.3.1 Solution # Connect to the Flight server local_client &lt;- flight_connect(host = &quot;127.0.0.1&quot;, port = 8089) # Send the data flight_put( local_client, data = airquality, path = &quot;pollution_data&quot; ) 8.4 Check what resources exist on a Flight server You want to see what paths are available on a Flight server. 8.4.1 Solution # Connect to the Flight server local_client &lt;- flight_connect(host = &quot;127.0.0.1&quot;, port = 8089) # Retrieve path listing list_flights(local_client) # [1] &quot;pollution_data&quot; 8.5 Retrieve data from a Flight server You want to retrieve data on a Flight server from a specified path. 8.5.1 Solution # Connect to the Flight server local_client &lt;- flight_connect(host = &quot;127.0.0.1&quot;, port = 8089) # Retrieve data flight_get( local_client, &quot;pollution_data&quot; ) # Table # 153 rows x 6 columns # $Ozone &lt;int32&gt; # $Solar.R &lt;int32&gt; # $Wind &lt;double&gt; # $Temp &lt;int32&gt; # $Month &lt;int32&gt; # $Day &lt;int32&gt; # # See $metadata for additional Schema metadata "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
